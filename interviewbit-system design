1. Storage Scalability Introduction
A sound understanding of storage scalability is really important if you intend to interview for a senior backend engineer or a senior infrastructure engineer role. 
We try to walk you through some of these problems here to set a tone around how to approach these problems. Do note that no design is correct or wrong. 
There are just good designs and bad designs which heavily depend on the use case. 
Hence, it is extremely important to clarify the requirements for the problem asked. We discuss this in more detail in later slides.

2. Pre Requisites
We assume in this section that you :
•  Have some experience working with a relational DB ( like MySQL ).
•  Have a basic idea about NoSQL DBs.
•  Understand the basics of the following : 
-  Concurrency : Do you understand threads, deadlock, and starvation? What happens when multiple processes / threads are trying to modify the same data? 
A basic understanding of read and write locks.
-  Networking : Do you roughly understand basic networking protocols like TCP and UDP? Do you understand the role of switches and routers?
-  File systems : You should understand the systems you’re building upon. Do you know roughly how an OS, file system, and database work? 
Do you know about the various levels of caching in a modern OS?

3. Basic Terminologies
- Replication
Replication refers to frequently copying the data across multiple machines. 
Post replication, multiple copies of the data exists across machines. This might help in case one or more of the machines die due to some failure.

- Consistency
Assuming you have a storage system which has more than one machine, consistency implies that the data is same across the cluster, 
so you can read or write to/from any node and get the same data.

- Eventual consistency
Exactly what the name suggests. In a cluster, if multiple machines store the same data, an eventual consistent model implies 
that all machines will have the same data eventually. Its possible that at a given instance, those machines have different versions of the same data 
( temporarily inconsistent ) but they will eventually reach a state where they have the same data.

- Availability
In the context of a database cluster, Availability refers to the ability to always respond to queries ( read or write ) irrespective of nodes going down.

- Partition Tolerance
In the context of a database cluster, cluster continues to function even if there is a “partition” (communications break) between two nodes 
(both nodes are up, but can’t communicate).

- Vertical scaling and Horizontal scaling
In simple terms, to scale horizontally is adding more servers. To scale vertically is to increase the resources of the server ( RAM, CPU, storage, etc. ). 
Example: Lets say you own a restaurant which is now exceeding its seating capacity. One way of accommodating more people ( scaling ) would be to add more and more chairs (scaling vertically). However since the space is limited, you won’t be able to add more chairs once the space is full. 
Another way of scaling would be to open new branches of the restaurant ( horizontal scaling ). 
Source : http://stackoverflow.com/questions/5401992/what-does-scale-horizontally-and-scale-vertically-mean

- Sharding
With most huge systems, data does not fit on a single machine. In such cases, sharding refers to splitting the very large database into smaller, 
faster and more manageable parts called data shards.

4. Cap Theorem
CAP Theorem states that in a distributed system, it is impossible to simultaneously guarantee all of the following:

•  Consistency
•  Availability
•  Partition Tolerance

